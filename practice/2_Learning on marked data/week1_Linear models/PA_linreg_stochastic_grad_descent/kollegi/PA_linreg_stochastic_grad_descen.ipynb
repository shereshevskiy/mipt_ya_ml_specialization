{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>48.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TV  Radio  Newspaper  Sales  Unnamed: 4\n",
       "0   1  230.1       37.8   69.2        22.1\n",
       "1   2   44.5       39.3   45.1        10.4\n",
       "2   3   17.2       45.9   69.3         9.3\n",
       "3   4  151.5       41.3   58.5        18.5\n",
       "4   5  180.8       10.8   58.4        12.9\n",
       "5   6    8.7       48.9   75.0         7.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ind</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>48.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ind     TV  Radio  Newspaper  Sales\n",
       "0    1  230.1   37.8       69.2   22.1\n",
       "1    2   44.5   39.3       45.1   10.4\n",
       "2    3   17.2   45.9       69.3    9.3\n",
       "3    4  151.5   41.3       58.5   18.5\n",
       "4    5  180.8   10.8       58.4   12.9\n",
       "5    6    8.7   48.9       75.0    7.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "# Файл \"неправильно\" скачался - со сдвигом колонок, поютому вынужден исправить\n",
    "adver_data.info \n",
    "adver_data = adver_data.rename(columns = {'TV':'Ind', 'Radio' : 'TV', 'Newspaper' : 'Radio', 'Sales':'Newspaper', \n",
    "                                          'Unnamed: 4':'Sales' })\n",
    "adver_data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(adver_data, columns = ['TV', 'Radio', 'Newspaper'])# Ваш код здесь\n",
    "\n",
    "y = pd.DataFrame(adver_data, columns = ['Sales']) # Ваш код здесь\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV           147.0425\n",
      "Radio         23.2640\n",
      "Newspaper     30.5540\n",
      "dtype: float64\n",
      "TV           85.639332\n",
      "Radio        14.809646\n",
      "Newspaper    21.724106\n",
      "dtype: float64\n",
      "X:  \n",
      "      TV  Radio  Newspaper\n",
      "0  230.1   37.8       69.2\n",
      "1   44.5   39.3       45.1\n",
      "2   17.2   45.9       69.3\n",
      "3  151.5   41.3       58.5\n",
      "4  180.8   10.8       58.4\n",
      "\"New\" X:   \n",
      "         TV     Radio  Newspaper\n",
      "0  0.969852  0.981522   1.778945\n",
      "1 -1.197376  1.082808   0.669579\n",
      "2 -1.516155  1.528463   1.783549\n",
      "3  0.052050  1.217855   1.286405\n",
      "4  0.394182 -0.841614   1.281802\n"
     ]
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "means, stds = np.mean(X, axis=0), np.std(X, axis=0)\n",
    "print means\n",
    "print stds\n",
    "print 'X:  '\n",
    "print X.head()\n",
    "col = ['TV','Radio','Newspaper']\n",
    "for i in range (3):\n",
    "    X[col[i]] = (X[col[i]] - means[i])/stds[i]  \n",
    "# Наверное три раза написать такую строчку было бы эффективнее,но в общем случае данный код компактнее\n",
    "print '\"New\" X:   '\n",
    "print X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.11160176 -1.39530685 -1.02439198]\n",
      " [ 1.          0.83440049 -1.20624088 -0.14518434]\n",
      " [ 1.         -1.06075676 -1.18598381 -0.03931117]\n",
      " [ 1.          1.64127273  1.33264499  1.89862818]\n",
      " [ 1.          1.24659427 -0.13261627 -0.02550162]\n",
      " [ 1.          0.67676264  1.47444446 -0.50423249]\n",
      " [ 1.         -0.08807285 -1.42906863 -0.18200979]\n",
      " [ 1.          0.51445404  0.36705807 -0.56867702]\n",
      " [ 1.          1.62258973 -0.63229062 -1.23613832]\n",
      " [ 1.         -1.49863967 -0.75383303 -0.32931159]\n",
      " [ 1.         -1.25576062  1.20435022 -1.13947151]\n",
      " [ 1.         -0.83539302 -0.84161366 -1.13026515]\n",
      " [ 1.         -1.51615499 -1.29402151  0.04814928]\n",
      " [ 1.          0.23070591  1.26512143 -1.2407415 ]\n",
      " [ 1.          0.0310313   0.83297064 -1.13026515]\n",
      " [ 1.         -1.27094056 -1.32103093 -0.771217  ]\n",
      " [ 1.         -0.61703541 -1.24000266 -1.03359834]\n",
      " [ 1.          0.34981006 -0.942899   -1.11185242]\n",
      " [ 1.          1.59456522  1.26512143  1.64085003]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# print X.head() \n",
    "a = X.shape\n",
    "b = np.ones((X.shape[0]))\n",
    "d = b.reshape(X.shape[0],1)\n",
    "#print d\n",
    "X = np.hstack((d,X))\n",
    "print X[180:199,:]\n",
    "\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2371625\n",
      "16.0\n"
     ]
    }
   ],
   "source": [
    "def mserror(y_fact, y_pred):\n",
    "    if len(y_fact) == len(y_pred):\n",
    "        s, s_pred = pd.Series(y_fact), pd.Series(y_pred)\n",
    "        c = (s-s_pred)*(s-s_pred)\n",
    "        return c.sum()/float(len(y_fact)) \n",
    "    else:\n",
    "        return \"Lenght Error\"\n",
    "\n",
    "# Проверка работы на примерe: вектор-столбец у с самим собой, увеличенным на 10 процентов. Результат - вектор столбец \n",
    "\n",
    "print mserror(y['Sales'], y['Sales']*1.1)\n",
    "# А это показывает, что функция работает и со строками (списками):\n",
    "print mserror ([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1], [5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5])\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.34575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Если я правильно понимаю задание y_pred - это вектор, состоящий из одинаковых членов, равных медиане вектора y\n",
    "e = np.median(y)\n",
    "e = np.ones (len(y))*e\n",
    "answer1 = mserror (y['Sales'], e) # Ваш код здесь\n",
    "print answer1\n",
    "write_answer_to_file(answer1, '1.txt')\n",
    "import math\n",
    "math.isnan(y['Sales'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best line\n",
      "[ 14.0225       3.91925365   2.79206274  -0.02253861]\n"
     ]
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "y = np.array(y)\n",
    "def normal_equation(dat, answ):\n",
    "    answ,dat = np.array(answ), np.array(dat)\n",
    "    #print answ\n",
    "    a = np.linalg.pinv(dat)\n",
    "    c = np.array (a.dot(answ))\n",
    "    return c[:,0]\n",
    "\n",
    "print 'The best line'\n",
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)\n",
    "\n",
    "# Функция np.multiply у меня никак не заработала.\n",
    "# На самом деле при определении функции правильно было бы заранее проверить размерности матриц, но я этого не сделал\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0225\n"
     ]
    }
   ],
   "source": [
    "answer2 = normal_equation(X, y) [0]  # поскольку  остальные члены линейной комбинации - нули, остается только свободный член\n",
    "# Ваш код здесь\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пресказание для оптимального вектора: \n",
      "[ 14.0225       3.91925365   2.79206274  -0.02253861]\n",
      "[ 20.52397441  12.33785482  12.30767078  17.59782951  13.18867186\n",
      "  12.47834763  11.72975995  12.12295317   3.72734086  12.55084872\n",
      "   7.0322992   17.28512918  10.57712073   8.82630048  18.43436638\n",
      "  20.81929952  12.82365674  23.22495716   9.95168206  14.16607293\n",
      "  18.10076728  14.7405382    6.4891503   16.5459329    8.14651887\n",
      "  15.6100386   14.98951429  17.05167344  19.41053803   9.14402389\n",
      "  21.6339338   11.3460929    7.63888314  18.86426829   7.57483051\n",
      "  17.00682618  23.40590052  15.62347779   9.90868103  20.44761039\n",
      "  16.37766467  17.2959832   21.59580326  13.96385684   8.88787996\n",
      "  15.16152314   8.87338673  21.7226299   16.26362018   8.1681656\n",
      "  12.63121132   9.33981296  20.66297563  19.94469957  20.37443008\n",
      "  21.2926106    8.52771254  12.77458802  21.89805198  18.13348698\n",
      "   5.74215558  22.89067208  16.78426073  13.21069202  16.97773556\n",
      "   7.84904532   9.01603163  12.0370073   18.97657924  21.10891244\n",
      "  17.77949782  10.62693815  10.36684881   9.90298206  17.32931197\n",
      "  11.85832174   4.47758904  13.81190223   8.81331353   9.67530328\n",
      "  11.44592364  14.64794093  10.17840799  14.42184212  20.78136464\n",
      "  15.18140789  11.59870739  15.59378475  11.71127101  16.92225511\n",
      "   9.99922965   4.49631598  19.15639616  21.22757378  10.48212385\n",
      "  16.31492112  12.63571716  15.33707782  24.11860723  16.94035021\n",
      "  13.87595844  23.24248685  17.64409385  14.76221142  20.30110878\n",
      "  17.93641467   6.12602215   7.10850249   3.58725841  19.69293106\n",
      "  14.7598741   21.14027498  13.88060985  16.40377623  15.30509593\n",
      "  12.91968895  11.97874744   6.5707774   15.56609348   6.82006767\n",
      "  14.41010605   7.83807642  13.6264571   15.0827909   19.45441306\n",
      "   9.12734958  10.57717411   6.599669    22.25549161   7.88410649\n",
      "  10.4276871   15.57779819   8.44915012  19.26692307  11.8368039\n",
      "  14.00141385  11.45348627  20.85125198   9.76842795  19.67547632\n",
      "   9.48964097  18.39902932  19.24986927   8.76480262  10.09133403\n",
      "   9.70853872  15.29422368  23.26086103  12.26335941   9.8272711\n",
      "  18.36720534  10.0095377   16.3600003   18.22390132  15.50161696\n",
      "   5.3075589   15.38485192  10.0143112   10.38419866  12.39914823\n",
      "  14.21383298  13.55914568  14.94678206  17.35163608  11.0682946\n",
      "  14.22372138  10.82439531  13.36324677  17.1861428   17.9415563\n",
      "   7.39497997  14.35827373   7.60769238  11.97093887  13.74435742\n",
      "  24.78687031  19.9793727   12.1620464   16.01099722  12.38455495\n",
      "  10.5871997   13.92809918   6.55467     24.13310013  18.53852096\n",
      "  20.80301059   9.69137313  17.07644223  18.64430648   6.05162411\n",
      "  12.4891591    8.42401933   4.46622956  18.48695797  16.49530044\n",
      "   5.37034248   8.16531236  12.78592082  23.76732149  15.17319554]\n",
      "Пример, который легко проверить: \n",
      "[ 6 12 18 30]\n"
     ]
    }
   ],
   "source": [
    "def linear_prediction(dat, w):\n",
    "    \n",
    "    return dat.dot(w)\n",
    "\n",
    "# Для примера получим вектор-строку прогнозов для случая, когда w - это решение нормального уравнения (т.е. оптимальный прогноз)\n",
    "print  u'Пресказание для оптимального вектора: '\n",
    "print normal_equation(X, y)\n",
    "print linear_prediction(X, normal_equation(X, y)) \n",
    "\n",
    "# а также применим функцию к примеру, на котором ее легко проверить\n",
    "a = np.array([[1,1,1],[2,2,2],[3,3,3],[4,5,6]])\n",
    "b = [2,2,2]\n",
    "print  u'Пример, который легко проверить: '\n",
    "print linear_prediction(a,b)\n",
    "\n",
    "#print  linear_prediction(X, [ -1.42225979e+39,  -7.82411383e+41,   7.04174736e+39, -2.45154901e+40]) \n",
    "\n",
    "# Приходится транспонировать матрицу, поскольку у меня был столбец\n",
    "    # Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "\n",
    "answer3 = mserror(y[:,0], linear_prediction(X, normal_equation(X, y)))\n",
    "print answer3\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00104    -0.00124527  0.00112612  0.00069636]\n",
      "[ 14.0226576    3.91940651   2.79221743  -0.02225824]\n"
     ]
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "def stochastic_gradient_step(iks, igrek, w, train_ind, eta=0.01):\n",
    "    dif = 2*(w[0]+w[1]*iks[train_ind,1] + w[2]*iks[train_ind,2] +w[3]*iks[train_ind,3] -  np.array(igrek)[train_ind,0])/len(igrek)\n",
    "    grad0 = dif\n",
    "    grad1 = dif*iks[train_ind,1]\n",
    "    grad2 = dif*iks[train_ind,2]\n",
    "    grad3 = dif*iks[train_ind,3]\n",
    "    #print 'grad =  ', eta *grad0, eta *grad1,eta *grad2, eta *grad3\n",
    "    return  w - eta * np.array([grad0, grad1, grad2, grad3])\n",
    "\n",
    "\n",
    "print stochastic_gradient_step(X, y, [0,0,0,0], 1 )\n",
    "print stochastic_gradient_step(X, y, normal_equation(X, y), 0, eta=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - максимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations ended on step  10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 8.842743  ,  2.48883009,  1.71429214,  0.43255158]),\n",
       " array([ 223.71625   ,  223.665389  ,  223.63640485, ...,   32.7954661 ,\n",
       "          32.79492837,   32.79016507])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stochastic_gradient_descent(iks, igrek, w_init, eta=1e-2, max_iter=1e4,min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    distance = []\n",
    "    y_forec = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        new_w = stochastic_gradient_step(iks, igrek, w, random_ind, eta=0.01)\n",
    "        iter_num = iter_num +1\n",
    "        weight_dist = ((new_w[0] - w[0])**2 + (new_w[1] - w[1])**2 + (new_w[2] - w[2])**2 + (new_w[3] - w[3])**2)**(1.0/2)\n",
    "        #distance = np.append(distance, weight_dist)\n",
    "        forecast = linear_prediction(iks, w)\n",
    "        w = new_w \n",
    "        #print forecast\n",
    "        #y_forec = np.append (y_forec, forecast)\n",
    "        error = mserror(y[:,0], forecast)\n",
    "        #if iter_num <= 10:\n",
    "            #print iter_num, random_ind, w, weight_dist, error,\"\\n\" \n",
    "        errors = np.append(errors,error)\n",
    "        if weight_dist < min_weight_dist:\n",
    "            print 'Halt because the distance is rather small'\n",
    "            return [w, errors]\n",
    "            exit()\n",
    "        if iter_num == max_iter:\n",
    "            print 'Iterations ended on step ', iter_num\n",
    "            return [w,  errors]\n",
    "            exit()\n",
    "    return [w,errors]\n",
    "iks, igrek, w_init = X, y, [0,0,0,0]\n",
    "stochastic_gradient_descent(iks, igrek, w_init, eta=1e-2, max_iter=1e4, min_weight_dist=1e-8, seed=42, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halt because the distance is rather small\n",
      "[  1.40190566e+01   3.91069256e+00   2.78209808e+00  -8.10462217e-03]\n",
      "[ 223.71625     223.665389    223.63640485 ...,    2.78441008    2.7844108\n",
      "    2.78441259]\n",
      "Wall time: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "example = [stochastic_gradient_descent(X, y, [0,0,0,0], eta=1e-2, max_iter=1e5, min_weight_dist=1e-8, seed=42, verbose=False)]\n",
    "stoch_grad_desc_weights = example[0][0]     \n",
    "print stoch_grad_desc_weights\n",
    "stoch_errors_by_iter = example[0][1] \n",
    "print stoch_errors_by_iter\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:161: UserWarning: pylab import has clobbered these variables: ['e']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xb2a6470>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8ebc470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "#print stoch_errors_by_iter\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xb296208>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEOCAYAAACaQSCZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8e86da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number', fontsize =14)\n",
    "ylabel('MSE',fontsize =14 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.40190566e+01,   3.91069256e+00,   2.78209808e+00,\n",
       "        -8.10462217e-03])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78441258835\n"
     ]
    }
   ],
   "source": [
    "print stoch_errors_by_iter[-1] #stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78441258841\n"
     ]
    }
   ],
   "source": [
    "answer4 = mserror (y[:,0], linear_prediction(X, stoch_grad_desc_weights))\n",
    "# print stoch_errors_by_iter\n",
    "#answer5 = np.min (stoch_errors_by_iter)\n",
    "print answer4\n",
    "# print answer5\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
