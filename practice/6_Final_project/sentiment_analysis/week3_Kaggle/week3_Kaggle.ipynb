{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Соревнование на Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание:   \n",
    "необходимо воспользоваться опытом предыдущих недель и побить бейзлайн в соревновании по сентимент-анализу отзывов на товары на Kaggle Inclass:\n",
    "\n",
    "https://inclass.kaggle.com/c/product-reviews-sentiment-analysis-light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# функция для записи submission  в папку data\n",
    "def write_submission(filename, pred):\n",
    "    pd.DataFrame(pred, columns=['y']).to_csv(path_or_buf='data/' + filename, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/products_sentiment_train.tsv', sep='\\t', header=None, names=['text', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was using the cheapie pail ... and it worked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0          2 . take around 10,000 640x480 pictures .       1\n",
       "1  i downloaded a trial version of computer assoc...       1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...       1\n",
       "3  i dont especially like how music files are uns...       0\n",
       "4  i was using the cheapie pail ... and it worked...       1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/products_sentiment_test.tsv', sep='\\t', header=0, names=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so , why the small digital elph , rather than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/4 way through the first disk we played on it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>better for the zen micro is outlook compatibil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6 . play gameboy color games on it with goboy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>likewise , i 've heard norton 2004 professiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  so , why the small digital elph , rather than ...\n",
       "1  3/4 way through the first disk we played on it...\n",
       "2  better for the zen micro is outlook compatibil...\n",
       "3    6 . play gameboy color games on it with goboy .\n",
       "4  likewise , i 've heard norton 2004 professiona..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выпишем итоги предыдущих недель, когда мы настраивали параметры:\n",
    "1. **vectorizer**: CountVectorizer() / TfidfVectorizer(): 0.841 / 0.821 --> **CountVectorizer()**\n",
    "2. **min_df** у CountVectorizer: 1 (default) / 10 / 50: 0.841/0.839/0.813 --> **1 (default)**\n",
    "3. **классификатор**: LogisticRegression / LinearSVC / SGDClassifier: 0.841 / 0.833 / 0.784 --> **LogisticRegression**\n",
    "4. **стоп-слова**: nltk.corpus.stopwords.words('english') / 'english': 0.8415 / 0,839 --> **nltk.corpus.stopwords.words('english')**\n",
    "5. **ngramm**: (1, 2), analyzer='word' (default) / (3, 5), analyzer='char_wb': 0.853 / 0.82 --> **(1, 2), analyzer='word'** (default)\n",
    "\n",
    "Сделаем предсказание с учетом этих параметров и отошлем на **Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 843 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CountVect = CountVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 2))\n",
    "logit = LogisticRegression()\n",
    "CountVect_logit = Pipeline([('CountVect', CountVect), ('logit', logit)])\n",
    "pred = CountVect_logit.fit(train['text'], train['target']).predict(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_submission('submiss_param_week12.csv', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle:** 0.77749    \n",
    "Ок, отправная точка ясна )   \n",
    "\n",
    "Будем подбирать параметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала посмотрим, чему равна **accuracy** на **кросс-валидации** при выбранных выше параметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_acc_score = 0.748498134363\n",
      "Wall time: 825 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CountVect = CountVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 2))\n",
    "logit = LogisticRegression()\n",
    "CountVect_logit = Pipeline([('CountVect', CountVect), ('logit', logit)])\n",
    "cv_acc_score = cross_val_score(CountVect_logit, train['text'], train['target'], cv=5).mean()\n",
    "print('cv_acc_score =', cv_acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем **ngram_range=(1, 3)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_acc_score = 0.747495634348\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CountVect = CountVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 3))\n",
    "logit = LogisticRegression()\n",
    "CountVect_logit = Pipeline([('CountVect', CountVect), ('logit', logit)])\n",
    "cv_acc_score = cross_val_score(CountVect_logit, train['text'], train['target'], cv=5).mean()\n",
    "print('cv_acc_score =', cv_acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эффекта нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем подбор параметров с помощью **hyperopt** (хотя здесь, наверное, и **GreadSearch** хватило бы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.425966259859712} accuracy_hyp = 0.7524943937149609\n",
      "Wall time: 44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# задаем предобработку и классификатор\n",
    "CountVect = CountVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 2))\n",
    "logit = LogisticRegression()\n",
    "CountVect_logit = Pipeline([('CountVect', CountVect), ('logit', logit)])\n",
    "\n",
    "# задаем функцию для опримизации\n",
    "def hyperopt_objective(params):\n",
    "    cv_acc_score = cross_val_score(CountVect_logit.set_params(logit__C=params['C']), train['text'], train['target'], cv=5).mean()\n",
    "    \n",
    "    return {'loss': - cv_acc_score, 'status': STATUS_OK}\n",
    "\n",
    "# задаем диапазоны подбора параметров\n",
    "params_space = {\n",
    "    'C': hp.loguniform('C', -4, 4), # default = 1.0\n",
    "                }\n",
    "\n",
    "# запускаем подбор\n",
    "trials = Trials()\n",
    "\n",
    "best_params = fmin(\n",
    "    hyperopt_objective,\n",
    "    space=params_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "accuracy_hyp = - trials.best_trial['result']['loss']\n",
    "print(best_params, 'accuracy_hyp =', accuracy_hyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**accuracy** немного улучшилась. Применим полученные параметры и сделаем посылку на **Kaggle**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 201 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CountVect = CountVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 2))\n",
    "logit = LogisticRegression()\n",
    "CountVect_logit = Pipeline([('CountVect', CountVect), ('logit', logit)])\n",
    "pred = CountVect_logit.set_params(logit__C=best_params['C']).fit(train['text'], train['target']).predict(test['text'])\n",
    "write_submission('submiss_C_hyper.csv', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle:** 0.77750    \n",
    "Особого улучшения пока нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем **TfidfVectorizer** с **analyzer='char', ngram_range=(3, 7)** и подбираем параметры через **GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 8.8899999999999988} best accuracy = 0.7755\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# задаем предобработку и классификатор\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), analyzer='char', ngram_range=(3, 7))\n",
    "X_train = vectorizer.fit_transform(train['text'])\n",
    "y_train = train['target']\n",
    "clf = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "              'C': np.linspace(0.01, 10, 100)             \n",
    "             }\n",
    "\n",
    "gridsearch = GridSearchCV(clf, param_grid, scoring='accuracy')\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(gridsearch.best_params_, 'best accuracy =', gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 357 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = vectorizer.transform(test['text'])\n",
    "pred = gridsearch.best_estimator_.predict(X_test)\n",
    "write_submission('submiss_Tfidf_LR_C.csv', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Kaggle:** 0.80500   \n",
    "ну вот и хорошо, **Simple benchmark** прошли!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим балансировку классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1274\n",
       "0     726\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем параметры более аккуратно, учтя при этом **балансировку** классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.0025950242113997372} best accuracy = 0.791\n",
      "Wall time: 7min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# задаем предобработку и классификатор\n",
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), analyzer='char', ngram_range=(3, 10))\n",
    "X_train = vectorizer.fit_transform(train['text'])\n",
    "y_train = train['target']\n",
    "clf = LogisticRegression(class_weight='balanced', random_state=17)\n",
    "\n",
    "param_grid = {\n",
    "              'C': np.logspace(-4, 3, 100)             \n",
    "             }\n",
    "\n",
    "gridsearch = GridSearchCV(clf, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(gridsearch.best_params_, 'best accuracy =', gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что еще можно сделать:\n",
    "- xgboost\n",
    "- предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_text = 0.744995609348\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), analyzer='char', ngram_range=(3, 10))\n",
    "transformer = TfidfTransformer()\n",
    "clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=17)\n",
    "text_clf = Pipeline([('vectorizer', vectorizer),\n",
    "                     ('transformer', transformer),\n",
    "                     ('clf', clf)])\n",
    "\n",
    "accuracy_text = cross_val_score(text_clf, train['text'], train['target'], cv=5).mean()\n",
    "print('accuracy_text =', accuracy_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем посылку с полученным **последним наилучшим результатом:    \n",
    "{'C': 0.0025950242113997372} best accuracy = 0.791**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), analyzer='char', ngram_range=(3, 10))\n",
    "X_train = vectorizer.fit_transform(train['text'])\n",
    "X_test = vectorizer.transform(test['text'])\n",
    "y_train = train['target']\n",
    "clf = LogisticRegression(class_weight='balanced', C=0.093260334688321997, random_state=17)\n",
    "\n",
    "pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "write_submission('submiss_LR_C093_bal_corr.csv', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Крайний вариант дал **Kaggle: 0.82250**   \n",
    "\n",
    "**Краткий анализ того, что получилось.**  \n",
    "Максимальный результат на сегодня получился при подборе 'С' без баланса, но при посылке на Kaggle при этом баланс **учитывали**. \n",
    "\n",
    "Этому предшествовали:    \n",
    "подбор на \"балансе\" дал `cv_score` **выше** подбора без баланса (**0.791** против **0.784**), но результат на Kaggle при этом получился **хуже** (**0.80750** против **0.81000**). А такая вот \"перекрестная\" посылка оказалась лучше! Вот такой неожиданный вывод."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поработаем с предобработкой текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого импортируем пакет для **стемминга**, то есть приведения всех слов к стандартному виду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "print(\" \".join(SnowballStemmer.languages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сделаем посылку с^ : полученным последним наилучшим результат\n"
     ]
    }
   ],
   "source": [
    "# пробуем\n",
    "stemmer_ru = SnowballStemmer('russian')\n",
    "print(stemmer_ru.stem('Сделаем посылку с^ : полученным последним наилучшим результатом'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.035111917342151307} best accuracy = 0.7835\n",
      "Wall time: 6min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# задаем предобработку и классификатор\n",
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), analyzer='char', ngram_range=(3, 10))\n",
    "stemmer = SnowballStemmer('english') # создаем класс для приведения слов к стандартному виду\n",
    "X_train = vectorizer.fit_transform(train['text'].apply(lambda s: stemmer.stem(s)))\n",
    "y_train = train['target']\n",
    "clf = LogisticRegression(random_state=17)\n",
    "\n",
    "param_grid = {\n",
    "              'C': np.logspace(-4, 3, 100)             \n",
    "             }\n",
    "\n",
    "gridsearch = GridSearchCV(clf, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(gridsearch.best_params_, 'best accuracy =', gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да..., пока стемминг улучшений не внес..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем убрать знаки препинания (некоторые, не все:   \n",
    "**)(!?** - оставляем, они могут тоже выражать настроение)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                take around           x    pictures  \n",
       "1    i downloaded a trial version of computer assoc...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# тестируем\n",
    "train['text'].head(2).apply(lambda s: re.sub(r'[0-9.,:/)(#\\']', ' ', s))\n",
    "# train['text'].head(2).apply(lambda s: re.sub('\\w', '', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.048626015800653531} best accuracy = 0.7825\n",
      "Wall time: 6min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# задаем предобработку и классификатор\n",
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), analyzer='char', ngram_range=(3, 10))\n",
    "stemmer = SnowballStemmer('english') # создаем класс для приведения слов к стандартному виду\n",
    "X_train = vectorizer.fit_transform(train['text'].apply(lambda s: stemmer.stem(re.sub(r'[.,:/#\\']', '', s))))\n",
    "y_train = train['target']\n",
    "clf = LogisticRegression(random_state=17)\n",
    "\n",
    "param_grid = {\n",
    "              'C': np.logspace(-4, 3, 100)             \n",
    "             }\n",
    "\n",
    "gridsearch = GridSearchCV(clf, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(gridsearch.best_params_, 'best accuracy =', gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поработаем с XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_text = 0.73001037019\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# задаем предобработку и классификатор\n",
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), analyzer='char', ngram_range=(3, 10))\n",
    "X_train = vectorizer.fit_transform(train['text'])\n",
    "y_train = train['target']\n",
    "clf = xgb.XGBClassifier(random_state=17)\n",
    "\n",
    "accuracy_text = cross_val_score(clf, X_train, y_train).mean()\n",
    "print('accuracy_text =', accuracy_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На дефолтных параметрах результат невысокий и считается достаточно долго ==> подбор будет тоже долгий. Пока оставим как есть.   \n",
    "**Итого:**   \n",
    "максимальный результат на **Kaggle - 0.82250** (это скорректированный, изначально был 0.81000)    \n",
    "Скриншот соревнования на **Kaggle:** https://prnt.sc/ie5baj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем НАИВНЫЙ БАЙЕС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_text = 0.792497895197\n",
      "Wall time: 5.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# задаем предобработку и классификатор\n",
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), analyzer='char', ngram_range=(3, 10))\n",
    "X_train = vectorizer.fit_transform(train['text'])\n",
    "y_train = train['target']\n",
    "clf = MultinomialNB(fit_prior=True)\n",
    "\n",
    "accuracy_text = cross_val_score(clf, X_train, y_train).mean()\n",
    "print('accuracy_text =', accuracy_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же, с **предобработкой текста**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_text = 0.79149614382\n",
      "Wall time: 5.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# задаем предобработку и классификатор\n",
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), analyzer='char', ngram_range=(3, 10))\n",
    "stemmer = SnowballStemmer('english') # создаем класс для приведения слов к стандартному виду\n",
    "X_train = vectorizer.fit_transform(train['text'].apply(lambda s: stemmer.stem(re.sub(r'[.,:/#\\'%@$^&*-+<>]', ' ', s))))\n",
    "y_train = train['target']\n",
    "clf = MultinomialNB(fit_prior=True)\n",
    "\n",
    "accuracy_text = cross_val_score(clf, X_train, y_train).mean()\n",
    "print('accuracy_text =', accuracy_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не улучшился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вспомогательная функция для отрисовки кривых валидации после запуска GridSearchCV (или RandomizedCV)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_validation_curves(param_values, grid_cv_results_):\n",
    "    train_mu, train_std = grid_cv_results_['mean_train_score'], grid_cv_results_['std_train_score']\n",
    "    valid_mu, valid_std = grid_cv_results_['mean_test_score'], grid_cv_results_['std_test_score']\n",
    "    train_line = plt.plot(param_values, train_mu, '-', label='train', color='green')\n",
    "    valid_line = plt.plot(param_values, valid_mu, '-', label='test', color='red')\n",
    "    plt.fill_between(param_values, train_mu - train_std, train_mu + train_std, edgecolor='none',\n",
    "                     facecolor=train_line[0].get_color(), alpha=0.2)\n",
    "    plt.fill_between(param_values, valid_mu - valid_std, valid_mu + valid_std, edgecolor='none',\n",
    "                     facecolor=valid_line[0].get_color(), alpha=0.2)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.96551724143103457} best accuracy = 0.792\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# задаем предобработку и классификатор\n",
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), analyzer='char', ngram_range=(3, 10))\n",
    "# stemmer = SnowballStemmer('english') # создаем класс для приведения слов к стандартному виду\n",
    "# X_train = vectorizer.fit_transform(train['text'].apply(lambda s: stemmer.stem(re.sub(r'[.,:/#\\']', '', s))))\n",
    "X_train = vectorizer.fit_transform(train['text'])\n",
    "y_train = train['target']\n",
    "clf = MultinomialNB()\n",
    "\n",
    "param_grid = {\n",
    "              'alpha': np.linspace(1e-10, 2, 30)             \n",
    "             }\n",
    "\n",
    "gridsearch = GridSearchCV(clf, param_grid, scoring='accuracy', return_train_score = True)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(gridsearch.best_params_, 'best accuracy =', gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGLrWXUYBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ae833decf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_validation_curves(param_grid['alpha'], gridsearch.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод по Наивному Байесу:**    \n",
    "Результат выше, чем у других классификаторов, наилучшее значение - при дефолтных параметрах.    \n",
    "Делаем посылку на Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), analyzer='char', ngram_range=(3, 10))\n",
    "X_train = vectorizer.fit_transform(train['text'])\n",
    "X_test = vectorizer.transform(test['text'])\n",
    "y_train = train['target']\n",
    "clf = MultinomialNB()\n",
    "\n",
    "pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "write_submission('submiss_NB_def.csv', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle:** 0.78250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### потестируем замену в регулярных выражениях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    snakeproject ru rubric article php art python reg exp'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(re.compile(r'http|[/:?.,_=]'), ' ', 'http://snakeproject.ru/rubric/article.php?art=python_reg_exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "здесь:    \n",
    "\"|\" в compile означает \"или\": или то, что слева (то есть http), или то что справа (то есть любой из символов в квадратных скобках)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\\n2\n"
     ]
    }
   ],
   "source": [
    "print(r'1\\n2') # префикс r - сырые данные (то есть \"как есть\", не учитывая метасимволы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print('1\\n2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "a = None # в ифе - как Фальш\n",
    "if a:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
