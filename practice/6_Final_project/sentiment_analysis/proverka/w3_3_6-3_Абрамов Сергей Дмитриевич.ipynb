{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание, оцениваемое сокурсниками: Соревнование по сентимент-анализу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вам нужно воспользоваться опытом предыдущих недель, чтобы побить бейзлайн в соревновании по сентимент-анализу отзывов на товары на Kaggle Inclass:\n",
    "\n",
    "https://inclass.kaggle.com/c/product-reviews-sentiment-analysis-light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве ответа в этом задании вам нужно загрузить ноутбук с решением и скриншот вашего результата на leaderboard.\n",
    "\n",
    "Убедитесь, что:\n",
    "\n",
    "1) ход вашего решения задокументирован достаточно подробно для того, чтобы ваши сокурсники поняли, что вы делали и почему,\n",
    "\n",
    "2) ваша команда в соревновании состоит только из вас и названа вашим логином на Сoursera, чтобы ваши сокурсники могли понять, что на скриншоте именно ваш результат\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сентимент-анализ отзывов на товары (простая версия)\n",
    "Классифицируйте отзывы по тональности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description: В этом соревновании вам предстоит прогнозировать по тексту отзыва его тональность: 1 - позитивная, 0 - негативная. В отличие от усложненной версии задачи, здесь вам не требуется самостоятельно собирать обучающую выборку - она есть в предоставляемых вам данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation: В качестве метрики качества используется accuracy. При валидации качества не забывайте, что ваш результат точно должен быть лучше, чем тривиальные ответы (всегда 0, всегда 1, случайный выбор класса)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "необходимые файлы\n",
    "\n",
    "products_sentiment_train.tsv - тренировочный сет\n",
    "\n",
    "products_sentiment_test.tsv - тестовый сет\n",
    "\n",
    "products_sentiment_sample_submission.csv - опример ответов тестового сета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n",
      "(2000, 2)\n",
      "1274\n",
      "726\n"
     ]
    }
   ],
   "source": [
    "#формируем тренировочный датасет из файла\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "train_data =  pd.DataFrame.from_csv('products_sentiment_train.tsv', sep='\\t', header = None, index_col=False)\n",
    "train_data.columns = ['review', 'class']\n",
    "print(train_data.shape)\n",
    "train_data.head()\n",
    "print(sum(train_data['class'] == 1))\n",
    "print(sum(train_data['class'] != 1))\n",
    "#формируем два списка: отзывы в текстовом формате и метки классов в виде чисел 1 или 0\n",
    "reviews_train = list(train_data['review'])\n",
    "class_train = list(train_data['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в тренировочном датасете мы имеем 2000 отзывов из них 1274 положительных и 726 отрицательных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1)\n"
     ]
    }
   ],
   "source": [
    "#формируем тестовый датасет из файла\n",
    "test_data =  pd.read_csv('products_sentiment_test.tsv', sep = \"\\t+\", index_col = 'Id', engine='python')\n",
    "print(test_data.shape)\n",
    "test_data.head()\n",
    "#формируем список: отзывы в текстовом формате\n",
    "reviews_test = list(test_data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в тестовом датасете мы имеем 500 отзывов, к какому классу они принадлежат, нам предлагается определить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "загружаем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707\n",
      "0.766\n",
      "0.7665\n",
      "0.7665\n",
      "0.754\n",
      "0.759\n",
      "0.754\n",
      "0.7405\n",
      "0.794\n"
     ]
    }
   ],
   "source": [
    "#пробовал выбирать вручную\n",
    "#CountVectorizer и LogisticRegression с параметрами по умолчанию\n",
    "text_clf1 = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "print(round(cross_val_score(text_clf1, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))\n",
    "\n",
    "\n",
    "#CountVectorizer и метод опорных векторов\n",
    "#previous score of 0.78500\n",
    "text_clf2 = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, n_iter=5))])\n",
    "print(round(cross_val_score(text_clf2, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))\n",
    "\n",
    "#CountVectorizer и метод Логистическая регрессия\n",
    "text_clf3 = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LogisticRegression())])\n",
    "print(round(cross_val_score(text_clf3, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))\n",
    "\n",
    "#TfidfVectorizer и метод Логистическая регрессия\n",
    "text_clf4 = Pipeline([('vect', TfidfVectorizer()),\n",
    "                       ('clf', LogisticRegression())])\n",
    "print(round(cross_val_score(text_clf4, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))\n",
    "\n",
    "#TfidfVectorizer и метод LinearSVC\n",
    "text_clf5 = Pipeline([('vect', CountVectorizer()),\n",
    "                       ('clf', LinearSVC())])\n",
    "print(round(cross_val_score(text_clf5, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))\n",
    "\n",
    "#CountVectorizer и метод опорных векторов + биграммы\n",
    "text_clf6 = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                     #('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, n_iter=5))])\n",
    "print(round(cross_val_score(text_clf6, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))\n",
    "\n",
    "#CountVectorizer и метод опорных векторов + н-граммы\n",
    "text_clf7 = Pipeline([('vect', CountVectorizer(ngram_range=(3, 5), analyzer='char_wb')),\n",
    "                     #('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, n_iter=5))])\n",
    "print(round(cross_val_score(text_clf7, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))\n",
    "\n",
    "#CountVectorizer и метод опорных векторов + н-граммы \n",
    "#Your submission scored 0.79250, which is an improvement of your previous score of 0.78500. Great job!\n",
    "text_clf8 = Pipeline([('vect', CountVectorizer(stop_words = 'english', ngram_range=(3, 5), analyzer='char_wb')),\n",
    "                     #('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, n_iter=5))])\n",
    "print(round(cross_val_score(text_clf8, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))\n",
    "\n",
    "#CountVectorizer и метод опорных векторов + н-граммы \n",
    "text_clf9 = Pipeline([('vect', CountVectorizer(stop_words = 'english', ngram_range=(2, 4), analyzer='char_wb')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, n_iter=50))])\n",
    "print(round(cross_val_score(text_clf9, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your submission scored 0.79250, which is not an improvement of your best score. Keep trying!\n",
    "с параметрами по умолчанию, или с настройками, подсмотренными из классификаторов других примеров, мы не можем достичь требуемого качества, поэтому на следующих шагах будем использовать поиск по сетке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7825\n"
     ]
    }
   ],
   "source": [
    "#сетка для векторайзера tfidf  и LogisticRegression\n",
    "%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents = None,\n",
    "                       lowercase = False,\n",
    "                       preprocessor = None)\n",
    "param_grid = [{'vect__ngram_range': [(1,1)],\n",
    "              'vect__stop_words': [stop, None],\n",
    "              'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              {'vect__ngram_range': [(1,1)],\n",
    "              'vect__stop_words': [stop, None],\n",
    "              'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'vect__use_idf':[False],\n",
    "               'vect__norm': [None],               \n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              ]\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                    ('clf',\n",
    "                    LogisticRegression(random_state=0))])\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                          scoring = 'accuracy',\n",
    "                          cv = 5, verbose = 1,\n",
    "                          n_jobs = 1)\n",
    "gs_lr_tfidf.fit(reviews_train, class_train)\n",
    "\n",
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print(round(cross_val_score(clf, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "качество работы (0,7825 - для лучшей связки векторизатор-классификатор из сетки) нас не устравает. Но уже на этом этапе мы достигли бейзлайна конкурса. Пробуем создать другую сетку (другие векторизаторы и классификаторы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your submission scored 0.80000\n",
    "[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
    "          lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
    "          ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
    "          stop_words=None, strip_accents=None, sublinear_tf=False,\n",
    "          token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "          tokenizer=<function tokenizer_porter at 0x000000000A345510>,\n",
    "          use_idf=True, vocabulary=None)),\n",
    " ('clf',\n",
    "  LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "            penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
    "            verbose=0, warm_start=False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3600 candidates, totalling 18000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 18000 out of 18000 | elapsed: 211.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7965\n"
     ]
    }
   ],
   "source": [
    "countvect = CountVectorizer(strip_accents = None,\n",
    "                       lowercase = False,\n",
    "                       preprocessor = None)\n",
    "param_grid = [{'vect__ngram_range': [(1,1),(1,2),(2,2),(1,3),(2,3)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter, None],\n",
    "               'clf__loss': ['hinge', 'log', 'modified_huber', 'squared_hinge'],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__alpha': [1e-3, 1e-4],\n",
    "               'clf__n_iter': [50,100,200]},\n",
    "              {'vect__ngram_range': [(1,1),(1,2),(2,2),(1,3),(2,3)],\n",
    "              'vect__stop_words': [stop, None],\n",
    "              'vect__tokenizer': [tokenizer, tokenizer_porter, None],\n",
    "              'clf__loss': ['hinge', 'log', 'modified_huber', 'squared_hinge'],\n",
    "              'clf__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "              'clf__alpha': [1e-3, 1e-4],\n",
    "              'clf__n_iter': [50,100,200]},\n",
    "              ]\n",
    "sgd_countv = Pipeline([('vect', countvect),\n",
    "                    ('clf',\n",
    "                    SGDClassifier(random_state=0))])\n",
    "gs_sgd_countv = GridSearchCV(sgd_countv, param_grid,\n",
    "                          scoring = 'accuracy',\n",
    "                          cv = 5, verbose = 1,\n",
    "                          n_jobs = 1)\n",
    "gs_sgd_countv.fit(reviews_train, class_train)\n",
    "\n",
    "clf = gs_sgd_countv.best_estimator_\n",
    "print(round(cross_val_score(clf, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "поиск по сетке CountVectorizer+SGDClassifier позволил достичь результата 0,81250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your submission scored 0.81250\n",
    "[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
    "          lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
    "          ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
    "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "          tokenizer=<function tokenizer_porter at 0x000000000A345510>,\n",
    "          vocabulary=None)),\n",
    " ('clf',\n",
    "  SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
    "         eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
    "         learning_rate='optimal', loss='hinge', n_iter=200, n_jobs=1,\n",
    "         penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
    "         warm_start=False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785\n"
     ]
    }
   ],
   "source": [
    "#лучший классификатор для сетки CountVectorizer+SGDClassifier\n",
    "text_clf_best_gs_sgd = Pipeline([('vect', CountVectorizer(stop_words = None, ngram_range=(1, 2),\n",
    "                                              analyzer = 'word', binary = False,\n",
    "                                              decode_error = 'strict', \n",
    "                                              #dtype= <class 'numpy.int64'>, \n",
    "                                              encoding='utf-8', input='content',\n",
    "                                              lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
    "                                              preprocessor=None, strip_accents=None, \n",
    "                                              token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                                              tokenizer=tokenizer_porter,\n",
    "                                              vocabulary=None)),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           average = False, class_weight = None,\n",
    "                                           epsilon = 0.1, eta0 = 0.0, \n",
    "                                           fit_intercept = True, l1_ratio = 0.15,\n",
    "                                           learning_rate = 'optimal',\n",
    "                                           shuffle = True, verbose = 0,\n",
    "                                           warm_start = False,\n",
    "                                           alpha=1e-3, n_iter=200))])\n",
    "print(round(cross_val_score(text_clf_best_gs_sgd, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793\n"
     ]
    }
   ],
   "source": [
    "text_clf_best_gs_sgd1 = Pipeline([('vect', CountVectorizer(stop_words = None, ngram_range=(1, 2),\n",
    "                                              analyzer = 'word', binary = False,\n",
    "                                              decode_error = 'strict', \n",
    "                                              #dtype= <class 'numpy.int64'>, \n",
    "                                              encoding='utf-8', input='content',\n",
    "                                              lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
    "                                              preprocessor=None, strip_accents=None, \n",
    "                                              token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                                              tokenizer=tokenizer_porter,\n",
    "                                              vocabulary=None)),\n",
    "                     ('clf', SGDClassifier(loss= 'hinge', penalty='l2',\n",
    "                                           average = True, class_weight = None,\n",
    "                                           epsilon = 0.1, eta0 = 0.0, \n",
    "                                           fit_intercept = True, l1_ratio = 0.15,\n",
    "                                           learning_rate = 'optimal',\n",
    "                                           shuffle = True, verbose = 0,\n",
    "                                           warm_start = False,\n",
    "                                           alpha=1e-3, n_iter=200))])\n",
    "print(round(cross_val_score(text_clf_best_gs_sgd1, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "на этом шаге я попробовал вручную поменять некоторые параметры, и мне удалось улучшить качество, изменив параметр average = True классификатора\n",
    "### Your submission scored 0.81500, which is an improvement of your previous score of 0.81250. Great job!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "попробуем создать сетку TfidfVectorizer+SGDCClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 320 out of 320 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents = None,\n",
    "                       lowercase = False,\n",
    "                       preprocessor = None)\n",
    "param_grid = [{'vect__ngram_range': [(1,1), (1,2)],\n",
    "              'vect__stop_words': [stop, None],\n",
    "              'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__loss': ['hinge', 'log', 'modified_huber', 'squared_hinge']},\n",
    "              ]\n",
    "sgd_tfidf = Pipeline([('vect', tfidf),\n",
    "                    ('clf',\n",
    "                    SGDClassifier(random_state=0))])\n",
    "gs_sgd_tfidf = GridSearchCV(sgd_tfidf, param_grid,\n",
    "                          scoring = 'accuracy',\n",
    "                          cv = 5, verbose = 1,\n",
    "                          n_jobs = 1)\n",
    "gs_sgd_tfidf.fit(reviews_train, class_train)\n",
    "clf = gs_sgd_tfidf.best_estimator_\n",
    "print(round(cross_val_score(clf, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "          token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=<function tokenizer_porter at 0x000000000A33F510>,\n",
       "          use_idf=True, vocabulary=None)),\n",
       " ('clf',\n",
       "  SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "         eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "         learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "         penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
       "         warm_start=False))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = gs_sgd_tfidf.best_estimator_\n",
    "#clf2 = gs_sgd_countv.best_estimator_\n",
    "clf3.steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
    "          lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
    "          ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
    "          stop_words=None, strip_accents=None, sublinear_tf=False,\n",
    "          token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "          tokenizer=<function tokenizer_porter at 0x000000000A345510>,\n",
    "          use_idf=True, vocabulary=None)),\n",
    " ('clf',\n",
    "  SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
    "         eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
    "         learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
    "         penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
    "         warm_start=False))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your submission scored 0.81500, which is not an improvement of your best score. Keep trying!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795\n"
     ]
    }
   ],
   "source": [
    "text_clf_best_gs_sgd2 = Pipeline([('vect', TfidfVectorizer(stop_words = None, ngram_range=(1, 2),\n",
    "                                              analyzer = 'word', binary = False,\n",
    "                                              decode_error = 'strict', \n",
    "                                              #dtype= <class 'numpy.int64'>, \n",
    "                                              encoding='utf-8', input='content',\n",
    "                                              lowercase=False, \n",
    "                                              norm = 'l2', smooth_idf=True,\n",
    "                                              max_df=1.0, max_features=None, min_df=1,\n",
    "                                              preprocessor=None, strip_accents=None, \n",
    "                                              sublinear_tf=False, use_idf=True,\n",
    "                                              token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                                              tokenizer=tokenizer_porter,\n",
    "                                              vocabulary=None)),\n",
    "                     ('clf', SGDClassifier(loss= 'hinge', penalty='l2',\n",
    "                                           average = False, class_weight = None,\n",
    "                                           epsilon = 0.1, eta0 = 0.0, \n",
    "                                           fit_intercept = True, l1_ratio = 0.15,\n",
    "                                           learning_rate = 'optimal',\n",
    "                                           shuffle = True, verbose = 0,\n",
    "                                           warm_start = False,\n",
    "                                           power_t=0.3,\n",
    "                                           alpha=1e-4, n_iter=100))])\n",
    "print(round(cross_val_score(text_clf_best_gs_sgd2, reviews_train, class_train, scoring=\"accuracy\", cv = 5).mean(),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "поиском по третьей сетке мы повторили наш лучший результат, на этом, наверное, пока и остановимся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#мы выбрали лучший классификатор, на нем формируем прогноз для тестовой выборки\n",
    "text_clf_best = text_clf_best_gs_sgd2\n",
    "text_clf_best.fit(reviews_train, class_train)\n",
    "predicted = text_clf_best.predict(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y\n",
       "Id   \n",
       "0   1\n",
       "1   0\n",
       "2   1\n",
       "3   1\n",
       "4   1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#на основе предсказанных значений классификатора формируем dataframe согласно примеру sample_submission\n",
    "#записываем его в файл sample_submission.csv, который загрузим в kaggle\n",
    "ans  = pd.DataFrame(predicted)\n",
    "ans.columns = ['y']\n",
    "ans.index.name = 'Id'\n",
    "ans.to_csv('products_sentiment_submission.csv')\n",
    "ans.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
