{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мой \"доморощенный\" парсер-паук"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсер сам ищет новую ссылку на текущей странице (начиная с начальной) и переползает на нее. Парсинг продолжается пока не спарсится заданное количество страниц или пока страницы не закончатся.   \n",
    "\n",
    "Примечание:    \n",
    "- между страницами можно вставлять (наверное) случайную задержку для иммитации естественного посещения страницы\n",
    "- при ошибке запроса - запрос на этот url повторяется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import scrapy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import bs4\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class TorgmailSpider(scrapy.Spider):\n",
    "class TorgmailSpider():\n",
    "    '''\n",
    "    start_url - начальный адрес\n",
    "    site - узел, с которого мы парсим данные\n",
    "    Методы:\n",
    "    .parse() - метод для парсинга\n",
    "    '''\n",
    "    \n",
    "    name = \"torgmail_spider\"\n",
    "    def __init__(self, start_url = 'https://torg.mail.ru/review/goods/mobilephones/', \n",
    "                site = 'https://torg.mail.ru') :\n",
    "        self.start_url = start_url\n",
    "        self.start_urls = [start_url]\n",
    "        self.site = site\n",
    "    \n",
    "    def parse_page(self, url, path_and_filename):\n",
    "        with open(path_and_filename, 'a') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "\n",
    "                # если возникает ошибка (страница не найдена (404) или запрос прерван (443) или еще что-то),\n",
    "                # то генерируется исключение и печатается сообщение об этом, но код не прерывается\n",
    "            \n",
    "            cycle_flag = True                     # организуем повтор запроса при сбое загрузки страницы\n",
    "            while cycle_flag:\n",
    "                try:                              # обрабатываем возможные исключения\n",
    "                    cycle_flag = False\n",
    "                    request = requests.get(url)\n",
    "                    request.raise_for_status()\n",
    "                except requests.exceptions.HTTPError as err:\n",
    "    #                     print('Oops. HTTP Error occured. Response is: {content} for url {url}'\n",
    "    #                           .format(content=err.response, url=url))\n",
    "        #                 print('Response is: {content}'.format(content=err.response.content))\n",
    "                    print('Oops. HTTP Error occured: %s' % err)\n",
    "                    cycle_flag = True\n",
    "                    continue\n",
    "                except requests.exceptions.ConnectionError as err1:\n",
    "        #                 print('ERROR: %s' % err1.args[0])\n",
    "                    print('Oops. Connection Error occured. Response is: {content} for url {url}'.format(content=err1.response, \n",
    "                                                                                                        url=url))\n",
    "                    cycle_flag = True\n",
    "                    continue\n",
    "                except requests.exceptions.RequestException as err2:\n",
    "        #                 print('ERROR: %s' % err2.args[0])\n",
    "                    print('Oops. RequestException Error occured. Response is: {content} for url {url}'\n",
    "                          .format(content=err2.response, \n",
    "                                                                                                        url=url))\n",
    "                    cycle_flag = True\n",
    "                    continue\n",
    "                else:\n",
    "                    text = request.text\n",
    "                    parser = bs4.BeautifulSoup(text, 'lxml')    \n",
    "\n",
    "                    for item in  parser.find_all('div', attrs={'class':'review-item'}):\n",
    "\n",
    "                        # \\t - заменяем на пробелы, так как табуляцию используем как разделитель (запятые и так в тексте есть)\n",
    "                        review = item.find('a', attrs={'class':'more'}).attrs['full-text'].replace('\\t', ' ') \\\n",
    "                                        if item.find('a', attrs={'class':'more'}) \\\n",
    "                                        else item.find('p', attrs={'class':\"review-item__paragraph\"}).text.replace('\\t', ' ')\n",
    "                        rating = float(item.find('span', attrs={'class':\"review-item__rating-counter\"}).text.replace(',', '.'))\n",
    "\n",
    "                        try:\n",
    "                            csvwriter.writerow([review, rating])\n",
    "                        except Exception as err3:\n",
    "                            print('Oops. Exception Error occured for url {url}. Response is: {content}'.format(url=url, \n",
    "                                                                                                               content=err3))    \n",
    "\n",
    "                    # формируем новую ссылку для \"переползания\" туда \"паука\"\n",
    "                    parse_for_next_page = parser.find('ul', attrs={'class':'pager-list js-pager'}\n",
    "                                                     ).find('a', attrs={'rel':'next'})\n",
    "                    if parse_for_next_page is not None:\n",
    "                        next_page = self.site + parse_for_next_page.attrs['href']\n",
    "                    else:\n",
    "                        next_page = False\n",
    "\n",
    "        return next_page\n",
    "\n",
    "    \n",
    "    def parse(self, num_pages=3, path_and_filename='tmp.csv'):\n",
    "        '''\n",
    "        num_pages: int или None \n",
    "                - число страниц для парсинга. Если None - страницы парсятся пока все не закончатся\n",
    "        path_and_filename: str \n",
    "                - путь и файл, куда сохраняем спарсенные данные\n",
    "        '''\n",
    "        with open(path_and_filename, 'w') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "            csvwriter.writerow(['review', 'rating']) # пишем заголовки колонок\n",
    "            \n",
    "            next_page = self.start_url\n",
    "            if num_pages is not None:\n",
    "                for n in tqdm_notebook(range(num_pages)):\n",
    "\n",
    "                    # сюда можно вставить случайную задержку для иммитации естественного посещения страницы\n",
    "                    next_page = self.parse_page(next_page, path_and_filename)\n",
    "                    if not next_page:\n",
    "                        print('\\nСтраницы для парсинга закончились')\n",
    "                        break\n",
    "            else:\n",
    "                while_flag = True\n",
    "                while while_flag:\n",
    "                    first_str = True\n",
    "                    if first_str:\n",
    "                        print('Парсинг первых 500 страниц:')\n",
    "                        first_str = False\n",
    "                    else:\n",
    "                        print('парсинг следующих 500 страниц:')\n",
    "                    for l in tqdm_notebook(range(500)):\n",
    "                        next_page = self.parse_page(next_page, path_and_filename)\n",
    "                        if not next_page:\n",
    "                            print('\\nВсе страницы для парсинга закончились')\n",
    "                            while_flag = False\n",
    "                            break\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### тестируем: тест 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Парсинг первых 500 страниц:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d24d6944e2459ba4bb7825e10f5fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oops. Connection Error occured. Response is: None for url https://torg.mail.ru/review/goods/mobilephones/?page=920\n",
      "\n",
      "Все страницы для парсинга закончились\n",
      "\n",
      "Wall time: 5.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torgmailSpider = TorgmailSpider('https://torg.mail.ru/review/goods/mobilephones/?page=920')\n",
    "torgmailSpider.parse(None, 'data/tmp.csv') # парсим 5 страниц"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### тестируем: тест 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262105173b0a44068cf761f1653f2f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Страницы для парсинга закончились\n",
      "\n",
      "Wall time: 3.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torgmailSpider = TorgmailSpider('https://torg.mail.ru/review/goods/mobilephones/?page=920')\n",
    "torgmailSpider.parse(10, 'data/tmp.csv') # парсим 5 страниц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>настроек захода в интернет через комп. МТС пор...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\r\\nЭтот телефон просто супер. Некоторые говор...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\r\\nНа мой взляд это самый подходящей тел. для...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\r\\nНедавно купила данный агрегат... Чтож, тел...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Очень хороший телефон....., качество сборки на...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating\n",
       "0  настроек захода в интернет через комп. МТС пор...     4.0\n",
       "1  \\r\\nЭтот телефон просто супер. Некоторые говор...     5.0\n",
       "2  \\r\\nНа мой взляд это самый подходящей тел. для...     4.0\n",
       "3  \\r\\nНедавно купила данный агрегат... Чтож, тел...     5.0\n",
       "4  Очень хороший телефон....., качество сборки на...     5.0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df_by_csv = pd.read_csv('data/tmp.csv', sep='\\t', index_col=None, header=0, encoding='cp1251')\n",
    "\n",
    "print(tmp_df_by_csv.shape)\n",
    "tmp_df_by_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ПРИМЕЧАНИЕ по поводу Scrapy**:   \n",
    "Если класс будет наследником **scrapy.Spider**, то кроме **определенных мною** методов добавляется еще куча методов, которые **уже** определены в scrapy.Spider и которые делают кучу разных полезных и хороших вещей, в том числе\n",
    "- запросы и поиск нужных элементов на странице на базе селекторов **CSS** и **XPath** и **встроенных** средств для запросов\n",
    "- плюс еще есть разные дополнительные возможности и настройки (работа с капчей, задержки при посещении страниц и т.д.)\n",
    "\n",
    "В моем же \"доморощенном\" пауке я это делаю вручную на базе библиотек **requests** и **BeautifulSoup** (вместо CSS и XPath) и (соответственно) **без** дополнительных фичей"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
