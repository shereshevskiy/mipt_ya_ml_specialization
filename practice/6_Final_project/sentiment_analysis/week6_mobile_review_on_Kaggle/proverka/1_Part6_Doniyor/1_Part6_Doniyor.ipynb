{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as regex\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for writing to file\n",
    "\n",
    "def AnswerWrite(prediction, filename):\n",
    "  #np.savetxt('np.csv', a, fmt='%.2f', delimiter=',', header=\" #1,  #2,  #3,  #4\")\n",
    "  answer = np.vstack([[i for i in np.arange(0, len(prediction),1)], prediction])\n",
    "  np.savetxt(filename, answer.T, fmt=\"%s\", delimiter=',', header=\"Id,y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/doniyor/Final_Project/Part6/test.csv') as f:\n",
    "    s = f.read()\n",
    "    test_final = pd.DataFrame({'Review':[item.text for item in bs4.BeautifulSoup(s,'lxml').findAll('review')]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/doniyor/Final_Project/Part6/Ispytano_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.Не плохо выглядит внешне, пока не работает ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+ Безусловно, цена.+ Наличие HDMI, подключал ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Картинка хорошая. На этом все достоинства зак...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>понравилось соответствие размеров экрана и це...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>высокое разрешение экрана, можно подключить к...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     class\n",
       "0   1.Не плохо выглядит внешне, пока не работает ...  positive\n",
       "1   + Безусловно, цена.+ Наличие HDMI, подключал ...  positive\n",
       "2   Картинка хорошая. На этом все достоинства зак...  positive\n",
       "3   понравилось соответствие размеров экрана и це...  positive\n",
       "4   высокое разрешение экрана, можно подключить к...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Cleaning\n",
    " * #### From special symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_symbols(data,column='Review'):\n",
    "    for remove in map(lambda r: regex.compile(regex.escape(r)), [\",\", \" : \", \"\\\"\", \"=\", \"&\", \";\", \"%\", \"$\",\n",
    "                                                                     \"@\", \"%\", \"^\", \"*\", \"{\", \"}\",\n",
    "                                                                     \"[\", \"]\", \"|\", \"/\", \"\\\\\", \">\", \"<\", \"-\",\n",
    "                                                                     #\"!\",\n",
    "                                                                     \"?\", \".\", \"'\",\n",
    "                                                                     \"--\", \"---\", \"#\",\n",
    "                                                                 \"(\", \")\",\n",
    "                                                                 ]):\n",
    "            data.loc[:, \"Review\"].replace(remove, \" \", inplace=True)    \n",
    "    return data\n",
    "def remove_by_regex(data ,regexp):\n",
    "        data.loc[:, \"Review\"].replace(regexp, \" \", inplace=True)\n",
    "        return data\n",
    "def remove_urls(data):\n",
    "        return remove_by_regex(data, regex.compile(r\"http.?://[^\\s]+[\\s]?\"))\n",
    "    \n",
    "def remove_usernames(data):\n",
    "        return remove_by_regex(data, regex.compile(r\"@[^\\s]+[\\s]?\"))\n",
    "def remove_numbers(data):\n",
    "        return remove_by_regex(data, regex.compile(r\"\\s?[0-9]+\\.?[0-9]*\"))\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_full(data):\n",
    "    data = clean_symbols(data)\n",
    "    data = remove_urls(data)\n",
    "    data = remove_usernames(data)\n",
    "    data = remove_numbers(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = clean_full(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Не плохо выглядит внешне  пока не работает  ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+ Безусловно  цена + Наличие HDMI  подключал ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Картинка хорошая  На этом все достоинства зак...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>понравилось соответствие размеров экрана и це...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>высокое разрешение экрана  можно подключить к...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     class\n",
       "0    Не плохо выглядит внешне  пока не работает  ...  positive\n",
       "1   + Безусловно  цена + Наличие HDMI  подключал ...  positive\n",
       "2   Картинка хорошая  На этом все достоинства зак...  positive\n",
       "3   понравилось соответствие размеров экрана и це...  positive\n",
       "4   высокое разрешение экрана  можно подключить к...  positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = Mystem()\n",
    "analyzerLem = CountVectorizer().build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatized_words(frame):\n",
    "        #arr = []\n",
    "        #for w in analyzerLem(frame):\n",
    "            #prepare = pos_prep(w)\n",
    "           # arr.append(lemmatizer.lemmatize(w))\n",
    "            \n",
    "        return lemmatizer.lemmatize(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CountVectorizer\n",
    "vectorizerCountLem = CountVectorizer(analyzer=lemmatized_words);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepare train and test datatest\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Review'], data['class'], test_size = 0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clflog = LogisticRegression();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vectorizer',vectorizerCountLem),('clf', clflog)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GridSearch parameters\n",
    "grid_params =     {\n",
    "     'vectorizer__min_df':[10],\n",
    "     'vectorizer__max_df':[500],\n",
    "     'vectorizer__analyzer':['word'],\n",
    "     'vectorizer__ngram_range':[(1,2)],\n",
    "     #'vectorizer__stop_words':[nltk.corpus.stopwords.words('english2')],\n",
    "    \n",
    "      'clf__C': [1.0,0.5,0.7,0.9,0.25,0.1],\n",
    "      'clf__penalty': ['l2','l1'],\n",
    "      'clf__class_weight': ['balanced']       \n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GridSearchCV\n",
    "grid = GridSearchCV(pipe, cv=3,scoring='accuracy', param_grid=grid_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9251930501930502"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = model.predict(test_final['Review'])\n",
    "res = ['neg' if (i == 'negative') else 'pos' for i in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AnswerWrite(prediction=res, filename='resSentiment2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Try dimention reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_count = vectorizerCountLem.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16573, 21638)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 21638 features\n",
    "data_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Projecting dataset to lower dimensions\n",
    "svd2000 = TruncatedSVD(n_components=2000,  random_state=42)\n",
    "data_2000 = svd2000.fit_transform(data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd1000 = TruncatedSVD(n_components=1000,  random_state=42)\n",
    "data_1000 = svd1000.fit_transform(data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd500 = TruncatedSVD(n_components=500, random_state=42)\n",
    "data_500 = svd500.fit_transform(data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd100 = TruncatedSVD(n_components=100,  random_state=42)\n",
    "data_100 = svd100.fit_transform(data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained 100:  0.980707425451 | Explained 500:  0.99105928908 | Explained 1000:  0.994851446009 | Explained 2000:  0.997618659644\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained 100: \", svd100.explained_variance_ratio_.sum(),\n",
    "      \"| Explained 500: \", svd500.explained_variance_ratio_.sum(),\n",
    "      \"| Explained 1000: \", svd1000.explained_variance_ratio_.sum(),\n",
    "      \"| Explained 2000: \", svd2000.explained_variance_ratio_.sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistik regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pipeline for 100 features\n",
    "pipelog_svd = Pipeline([('vectorizer',vectorizerCountLem),('svd', svd100),('clf',clflog)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_cr = cross_val_score(estimator=pipelog_svd,X=X_train,y=y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer=<function lemmatized_words at 0x7f3b04922158>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), prep...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelog_svd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_acc = accuracy_score(pipelog_svd.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val mean logistic regression:  0.869244934759  | Validation on test set:  0.877654440154\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross val mean logistic regression: \",log_cr.mean(), \" | Validation on test set: \", log_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pipeline for Random Forest on 500 features\n",
    "clfRF = RandomForestClassifier(n_estimators=1000)\n",
    "pipeRF = Pipeline([('vectorizer',vectorizerCountLem),('svd', svd500),('clf',clfRF)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cr = cross_val_score(estimator=pipeRF,X=X_train,y=y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeRF.fit(X_train, y_train)\n",
    "rf_acc = accuracy_score(pipeRF.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross val mean random forest: \",rf_cr.mean(), \" | Validation on test set: \", rf_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "* MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mds = manifold.MDS(n_components = 2, n_init = 1, max_iter = 1000)\n",
    "data_2d_mds = mds.fit_transform(data_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pylab.figure(figsize=(10, 6))\n",
    "pylab.scatter(data_2d_mds[:, 0], data_2d_mds[:, 1], c = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "#### Best result is 94% with Logistic Regression with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
